{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de34bfc-49c6-489a-a7a8-c7af85d346f3",
   "metadata": {},
   "source": [
    "<a href='https://huggingface.co/learn/nlp-course/chapter7/7?fw=pt'> huggingface 1</a> </br>\n",
    "<a href='https://huggingface.co/docs/transformers/v4.32.0/ko/tasks/question_answering'> huggingface 2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7cde3e-58e0-4426-9a7f-d531a740081e",
   "metadata": {},
   "source": [
    "# Preparing the data - SQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4af029-f69c-4d72-b85e-70de38348cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu118'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012d63fa-e580-4c5a-9e78-f4636a8e996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e93528-0a31-4a33-bdce-72528d07e961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b769bda-e5fd-418f-b485-c62f9f3b1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Context:  <class 'str'>\n",
      "* Question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "* Answer:  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n",
      "* Title:  University_of_Notre_Dame\n"
     ]
    }
   ],
   "source": [
    "\"\"\"첫 번째 data 출력\"\"\"\n",
    "print(\"* Context: \", raw_datasets[\"train\"][0][\"context\"])\n",
    "print(\"* Question: \", raw_datasets[\"train\"][0][\"question\"])\n",
    "print(\"* Answer: \", raw_datasets[\"train\"][0][\"answers\"])\n",
    "print(\"* Title: \", raw_datasets[\"train\"][0][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c5a980-1c67-41dc-839b-3c03e08a8aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Context와 question field는 사용하기 편리하다. 반면에 answer field는 dic 형태여서 복잡하다.\n",
    "Training 중에는, 가능한 답변이 하나뿐이므로 filter()를 사용해서 제거\n",
    "즉, train dataset에서 정답(answer-text)이 복수 정답인 context가 있는지 확인.\n",
    "\"\"\"\n",
    "raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7247a358-1f5c-4fa7-9952-fb7ed81ee7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"이미 train dataset이 잘 구성되어 있기 때문에 수정하지 않아도 된다.\"\"\"\n",
    "len(raw_datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5652bdf3-9ec1-4261-a5e6-9e9c15684d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}\n",
      "{'text': ['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"], 'answer_start': [403, 355, 355]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "반면에, evaluation dataset은 가능한 답변이 여러 개 존재할 수 있다.\n",
    "Validation dataset의 0, 2 번째 index 답 출력 \n",
    "\"\"\"\n",
    "\n",
    "print(raw_datasets[\"validation\"][0][\"answers\"])\n",
    "print(raw_datasets[\"validation\"][2][\"answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851b177f-f254-4fc6-84c9-ca66057d8b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'evaluation dataset의 경우, 깊게 다루지 않고 Datasets metric으로 간단하게 처리한다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"evaluation dataset의 경우, 깊게 다루지 않고 Datasets metric으로 간단하게 처리한다.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437d0a4-b404-46e1-a1b7-e63e76a6abd6",
   "metadata": {},
   "source": [
    "# Training data preprocessing\n",
    "질문의 답변에 대한 label을 생성하는 것이 어렵다. 이 레이블은 답변에 해당하는 토큰의 시작 및 끝 위치가 될 것이다. </br>\n",
    "우선, 모델이 이해할 수 있는 ID로 Text를 변환해야 한다. 이를 위해서 <strong>Tokenizer</strong>를 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3ad0d7-f460-4878-949b-3c49233cc692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\" # distilbert-base-cased-distilled-squad\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c658e12-c7c0-4044-ac7d-4c8a7ffb8f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"토큰화가 빠르게 구현되어 있는지 확인\"\"\"\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65bfc8-2cef-4730-86fe-70c38f6bb1a7",
   "metadata": {},
   "source": [
    "### BERT의 input은 [CLS] sentence_A [SEP] sentence_B [SEP] 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ccfc13a-eb9d-41d6-9eb9-34b4ddc6e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] architecturally, the school has a catholic character. atop the main building\\'s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Tokenizer로 check\"\"\"\n",
    "context = raw_datasets[\"train\"][0][\"context\"]\n",
    "question = raw_datasets[\"train\"][0][\"question\"]\n",
    "\n",
    "\"\"\"[CLS] question [SEP] context [SEP]로 변형(id 형태로)\"\"\"\n",
    "inputs = tokenizer(question, context)\n",
    "\"\"\"ID 형태를 다시 원래 text로 decoding\"\"\"\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deedaf7b-a189-4d02-b676-c073b2950b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*이 부분에서는 질문 응답 작업을 위한 라벨을 생성하는 방법과 훈련 데이터의 문맥이 \\n모델의 최대 길이(여기서는 384)를 초과할 수 있는 경우를 처리하는 방법을 설명하고 있습니다.\\n\\n*질문 응답 모델의 목표는 주어진 텍스트 내에서 정답의 시작 및 끝 토큰의 인덱스를 예측하는 것입니다. \\n따라서 각 토큰에 대한 시작 및 끝 위치 예측을 수행하도록 모델을 훈련해야 합니다.\\n\\n*일부 예제의 문맥이 매우 길기 때문에 이를 처리하기 위해 슬라이딩 윈도우 방식을 사용합니다. \\n현재 예제에서는 문맥의 최대 길이를 100으로 제한하고, 50개의 토큰을 가진 슬라이딩 윈도우를 사용하여 처리합니다. \\n슬라이딩 윈도우 처리 방식은 문맥을 여러 개의 작은 조각으로 나누어 처리하는 것을 의미하며, 각 조각에 대한 예측을 수행합니다.\\n\\n*또한 max_length를 사용하여 최대 길이를 설정하고, \\ntruncation을 \"only_second\"로 설정하여 문맥(두 번째 위치)이 질문과 함께 너무 길 경우 문맥을 자르고, \\nstride를 사용하여 두 연속적인 조각 간의 겹치는 토큰 수를 설정하며, \\nreturn_overflowing_tokens를 True로 설정하여 넘친 토큰을 유지하도록 tokenizer에 알립니다.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "*이 부분에서는 질문 응답 작업을 위한 라벨을 생성하는 방법과 훈련 데이터의 문맥이 \n",
    "모델의 최대 길이(여기서는 384)를 초과할 수 있는 경우를 처리하는 방법을 설명하고 있습니다.\n",
    "\n",
    "*질문 응답 모델의 목표는 주어진 텍스트 내에서 정답의 시작 및 끝 토큰의 인덱스를 예측하는 것입니다. \n",
    "따라서 각 토큰에 대한 시작 및 끝 위치 예측을 수행하도록 모델을 훈련해야 합니다.\n",
    "\n",
    "*일부 예제의 문맥이 매우 길기 때문에 이를 처리하기 위해 슬라이딩 윈도우 방식을 사용합니다. \n",
    "현재 예제에서는 문맥의 최대 길이를 100으로 제한하고, 50개의 토큰을 가진 슬라이딩 윈도우를 사용하여 처리합니다. \n",
    "슬라이딩 윈도우 처리 방식은 문맥을 여러 개의 작은 조각으로 나누어 처리하는 것을 의미하며, 각 조각에 대한 예측을 수행합니다.\n",
    "\n",
    "*또한 max_length를 사용하여 최대 길이를 설정하고, \n",
    "truncation을 \"only_second\"로 설정하여 문맥(두 번째 위치)이 질문과 함께 너무 길 경우 문맥을 자르고, \n",
    "stride를 사용하여 두 연속적인 조각 간의 겹치는 토큰 수를 설정하며, \n",
    "return_overflowing_tokens를 True로 설정하여 넘친 토큰을 유지하도록 tokenizer에 알립니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e1a344-91a3-4c00-98db-f22a601bdde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the gr [SEP]\n",
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint [SEP]\n",
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome [SEP]\n",
      "[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train dataset의 zero index data(question, context)를 tokenizer에게 전달 -> ID 형태로 변환\"\"\"\n",
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    ")\n",
    "\n",
    "\"\"\"ID를 다시 text로 변환해서 출력\"\"\"\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994ca0c9-c403-4f08-b894-0b770e25d67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*이 예제는 네 개의 입력으로 분할되었습니다. \\n각 입력은 질문과 일부 문맥을 포함하고 있습니다. \\n질문에 대한 답변 (\"Bernadette Soubirous\")은 세 번째와 마지막 입력에서만 나타나므로 이렇게 긴 문맥을 처리하면 \\n답변이 문맥에 포함되지 않은 훈련 예제가 생성됩니다. \\n이러한 경우 레이블은 start_position = end_position = 0으로 설정됩니다([CLS] 토큰을 예측하게 됩니다). \\n또한, 답변이 잘리면(시작 또는 끝 부분만 있는 경우) 해당 레이블도 0으로 설정됩니다. \\n답변이 완전히 문맥에 포함된 경우 레이블은 답변이 시작하는 토큰과 답변이 끝나는 토큰의 인덱스가 됩니다.\\n\\n*데이터셋은 답변의 시작 위치를 문맥에서 제공하며, 답변의 길이를 추가함으로써 답변의 끝 위치를 찾을 수 있습니다. \\n이러한 위치를 토큰 인덱스로 매핑하려면 offset 매핑을 사용해야 합니다. \\nreturn_offsets_mapping=True를 사용하여 tokenizer로부터 이러한 offset 매핑을 얻을 수 있습니다.\\n\\n*즉, answer span이 context에 같이 존재하지 않으면 (0,0)의 index를 반환한다.\\n또한, 같은 context임을 알려주기 위해 offset을 도입.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "*이 예제는 네 개의 입력으로 분할되었습니다. \n",
    "각 입력은 질문과 일부 문맥을 포함하고 있습니다. \n",
    "질문에 대한 답변 (\"Bernadette Soubirous\")은 세 번째와 마지막 입력에서만 나타나므로 이렇게 긴 문맥을 처리하면 \n",
    "답변이 문맥에 포함되지 않은 훈련 예제가 생성됩니다. \n",
    "이러한 경우 레이블은 start_position = end_position = 0으로 설정됩니다([CLS] 토큰을 예측하게 됩니다). \n",
    "또한, 답변이 잘리면(시작 또는 끝 부분만 있는 경우) 해당 레이블도 0으로 설정됩니다. \n",
    "답변이 완전히 문맥에 포함된 경우 레이블은 답변이 시작하는 토큰과 답변이 끝나는 토큰의 인덱스가 됩니다.\n",
    "\n",
    "*데이터셋은 답변의 시작 위치를 문맥에서 제공하며, 답변의 길이를 추가함으로써 답변의 끝 위치를 찾을 수 있습니다. \n",
    "이러한 위치를 토큰 인덱스로 매핑하려면 offset 매핑을 사용해야 합니다. \n",
    "return_offsets_mapping=True를 사용하여 tokenizer로부터 이러한 offset 매핑을 얻을 수 있습니다.\n",
    "\n",
    "*즉, answer span이 context에 같이 존재하지 않으면 (0,0)의 index를 반환한다.\n",
    "또한, 같은 context임을 알려주기 위해 offset을 도입.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7c3457-59a1-49ee-89f4-634da9be96c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True, # 이전 예제에서 추가된 요소\n",
    ")\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b0cfeb-84ff-4180-953f-d6d9cdf8eb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n여기서 보듯이 우리는 일반적인 입력 ID, 토큰 유형 ID, 어텐션 마스크를 얻을 수 있으며, \\n필요한 offset 매핑과 추가적인 overflow_to_sample_mapping 키를 얻습니다. \\n해당 값은 여러 개의 텍스트를 동시에 토큰화할 때 유용하며 (tokenizer가 Rust로 백엔드 처리를 지원하기 때문에 이렇게 하는 것이 좋습니다), \\n각 피처를 원본에서 유래한 예제에 매핑합니다. \\n이 예에서는 하나의 예제만 토큰화했기 때문에 0의 목록을 얻습니다.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "여기서 보듯이 우리는 일반적인 입력 ID, 토큰 유형 ID, 어텐션 마스크를 얻을 수 있으며, \n",
    "필요한 offset 매핑과 추가적인 overflow_to_sample_mapping 키를 얻습니다. \n",
    "해당 값은 여러 개의 텍스트를 동시에 토큰화할 때 유용하며 (tokenizer가 Rust로 백엔드 처리를 지원하기 때문에 이렇게 하는 것이 좋습니다), \n",
    "각 피처를 원본에서 유래한 예제에 매핑합니다. \n",
    "이 예에서는 하나의 예제만 토큰화했기 때문에 0의 목록을 얻습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "428d48f4-ec4d-4554-830b-74f60475b486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"같은 context임을 알려준다\"\"\"\n",
    "inputs[\"overflow_to_sample_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49489fff-5ad5-4032-b9b0-23b2daa56a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 examples gave 17 features.\n",
      "Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3].\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    raw_datasets[\"train\"][2:6][\"question\"],\n",
    "    raw_datasets[\"train\"][2:6][\"context\"],\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\n",
    "print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e55000e-ab9f-4b86-bef6-08973c16d7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n*이전에 언급한대로 레이블은 다음과 같습니다.\\n    (0, 0) : 답이 해당 컨텍스트 부분에 없을 경우\\n    (start_position, end_position) : 답이 해당 컨텍스트 부분에 있을 경우, \\n                                     start_position은 답의 시작 지점을 나타내는 토큰의 인덱스이며, \\n                                     end_position은 답의 끝 지점을 나타내는 토큰의 인덱스입니다.\\n\\n*이 상황을 판단하고 필요한 경우 토큰의 위치를 찾기 위해, 먼저 입력 ID에서 컨텍스트의 시작과 끝을 나타내는 토큰 인덱스를 찾습니다. \\n토큰 유형 ID를 사용할 수 있지만, 이 모든 모델에서 필요하지 않을 수 있으므로 (예를 들어 DistilBERT는 필요로하지 않음), \\n대신 tokenizer가 반환하는 BatchEncoding의 sequence_ids() 메서드를 사용합니다.\\n\\n*한 번 이러한 토큰 인덱스를 얻으면 해당 오프셋을 확인하며, \\n이것은 원본 컨텍스트 내의 문자 범위를 나타내는 두 정수로 구성된 튜플입니다. \\n이로써 해당 기능의 컨텍스트 부분이 답변 이후에 시작하거나 답변 시작 이전에 끝날 경우 (0, 0) 레이블이라고 판단할 수 있습니다. \\n그렇지 않은 경우, 답의 첫 번째 토큰과 마지막 토큰을 찾기 위해 루프를 돕니다.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "*이전에 언급한대로 레이블은 다음과 같습니다.\n",
    "    (0, 0) : 답이 해당 컨텍스트 부분에 없을 경우\n",
    "    (start_position, end_position) : 답이 해당 컨텍스트 부분에 있을 경우, \n",
    "                                     start_position은 답의 시작 지점을 나타내는 토큰의 인덱스이며, \n",
    "                                     end_position은 답의 끝 지점을 나타내는 토큰의 인덱스입니다.\n",
    "\n",
    "*이 상황을 판단하고 필요한 경우 토큰의 위치를 찾기 위해, 먼저 입력 ID에서 컨텍스트의 시작과 끝을 나타내는 토큰 인덱스를 찾습니다. \n",
    "토큰 유형 ID를 사용할 수 있지만, 이 모든 모델에서 필요하지 않을 수 있으므로 (예를 들어 DistilBERT는 필요로하지 않음), \n",
    "대신 tokenizer가 반환하는 BatchEncoding의 sequence_ids() 메서드를 사용합니다.\n",
    "\n",
    "*한 번 이러한 토큰 인덱스를 얻으면 해당 오프셋을 확인하며, \n",
    "이것은 원본 컨텍스트 내의 문자 범위를 나타내는 두 정수로 구성된 튜플입니다. \n",
    "이로써 해당 기능의 컨텍스트 부분이 답변 이후에 시작하거나 답변 시작 이전에 끝날 경우 (0, 0) 레이블이라고 판단할 수 있습니다. \n",
    "그렇지 않은 경우, 답의 첫 번째 토큰과 마지막 토큰을 찾기 위해 루프를 돕니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c1a067f-2671-4a61-9bdc-9b888372ff3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([81, 49, 17, 0, 0, 57, 19, 33, 0, 0, 0, 63, 27, 0, 0, 0, 0],\n",
       " [83, 51, 19, 0, 0, 63, 25, 39, 0, 0, 0, 64, 28, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = raw_datasets[\"train\"][2:6][\"answers\"]\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n",
    "    answer = answers[sample_idx]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # Find the start and end of the context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "        idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "        idx += 1\n",
    "    context_end = idx - 1\n",
    "\n",
    "    # If the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # Otherwise it's the start and end token positions\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfd7dfe4-3cc3-4fcf-be98-9eabfc317272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n우리의 접근 방법이 올바른지 확인하기 위해 몇 가지 결과를 살펴보겠습니다. \\n첫 번째 feature에서 우리는 (83, 85) 레이블을 찾아, 83에서 85까지(포함) 토큰의 디코드된 범위와 이론적인 답변을 비교해 보겠습니다.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "우리의 접근 방법이 올바른지 확인하기 위해 몇 가지 결과를 살펴보겠습니다. \n",
    "첫 번째 feature에서 우리는 (83, 85) 레이블을 찾아, 83에서 85까지(포함) 토큰의 디코드된 범위와 이론적인 답변을 비교해 보겠습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41dd9443-2646-4c99-95fb-badbdef309ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: the Main Building, labels give: the main building\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "start = start_positions[idx]\n",
    "end = end_positions[idx]\n",
    "labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8146e00-05c5-42d7-9fd6-bd4da66a55ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n이건 일치하는 경우입니다.\\n이제 인덱스 4를 확인해보면 거기서는 레이블을 (0, 0)으로 설정했기 때문에, 해당 feature의 컨텍스트 청크에 답변이 포함되어 있지 않음을 의미합니다.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "이건 일치하는 경우입니다.\n",
    "이제 인덱스 4를 확인해보면 거기서는 레이블을 (0, 0)으로 설정했기 때문에, 해당 feature의 컨텍스트 청크에 답변이 포함되어 있지 않음을 의미합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9360f79a-5ab3-43e6-ad69-2aa62b2ee264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] what is the grotto at notre dame? [SEP] architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of [SEP]\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "decoded_example = tokenizer.decode(inputs[\"input_ids\"][idx])\n",
    "print(f\"Theoretical answer: {answer}, decoded example: {decoded_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc9a39c-d309-4ad6-bc04-87f523fca85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n네, 이 특정한 feature의 컨텍스트 안에 \"Bernadette Soubirous\"라는 정답이 포함되어 있지 않으므로 이 경우 레이블이 (0, 0)으로 설정됩니다. \\n이것은 예상된 동작과 일치합니다. 이 feature의 컨텍스트 내에 정답이 없기 때문에 레이블이 (0, 0)으로 설정된 것입니다.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "네, 이 특정한 feature의 컨텍스트 안에 \"Bernadette Soubirous\"라는 정답이 포함되어 있지 않으므로 이 경우 레이블이 (0, 0)으로 설정됩니다. \n",
    "이것은 예상된 동작과 일치합니다. 이 feature의 컨텍스트 내에 정답이 없기 때문에 레이블이 (0, 0)으로 설정된 것입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d8aee67-e65b-447d-b52c-eb2697fc5a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n전체 교육 데이터셋에 적용할 함수를 작성할 차례입니다. \\n대부분의 컨텍스트가 길기 때문에 (그에 해당하는 샘플이 여러 feature로 분할될 것입니다) 모든 feature를 설정한 최대 길이로 패딩합니다. \\n동적 패딩을 적용하는 것에는 실제로 이득이 없기 때문입니다.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "전체 교육 데이터셋에 적용할 함수를 작성할 차례입니다. \n",
    "대부분의 컨텍스트가 길기 때문에 (그에 해당하는 샘플이 여러 feature로 분할될 것입니다) 모든 feature를 설정한 최대 길이로 패딩합니다. \n",
    "동적 패딩을 적용하는 것에는 실제로 이득이 없기 때문입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af323ce-b4ee-482d-90cd-d71019742a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "143c3312-e2f5-4758-92d6-291425635372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n최대 길이 및 슬라이딩 창의 길이를 결정하는 두 개의 상수를 정의하고 토큰화하기 전에 약간의 정리를 추가로 수행했다는 점을 유의하세요. \\nSQuAD 데이터셋의 일부 질문은 아무런 내용을 추가하지 않지만 (RoBERTa와 같은 모델을 사용할 때 토큰화될 때 공간을 차지함) \\n시작과 끝에 추가 공백이 있으므로 이러한 추가 공백을 제거했습니다.\\n\\n이 기능을 전체 교육 세트에 적용하려면 Dataset.map() 메서드를 batched=True 플래그와 함께 사용해야 합니다. \\n이것은 데이터셋의 길이를 변경하는 작업이기 때문에 여기에서 필요한 작업입니다. 하나의 예제가 여러 교육 피처를 생성할 수 있기 때문입니다.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "최대 길이 및 슬라이딩 창의 길이를 결정하는 두 개의 상수를 정의하고 토큰화하기 전에 약간의 정리를 추가로 수행했다는 점을 유의하세요. \n",
    "SQuAD 데이터셋의 일부 질문은 아무런 내용을 추가하지 않지만 (RoBERTa와 같은 모델을 사용할 때 토큰화될 때 공간을 차지함) \n",
    "시작과 끝에 추가 공백이 있으므로 이러한 추가 공백을 제거했습니다.\n",
    "\n",
    "이 기능을 전체 교육 세트에 적용하려면 Dataset.map() 메서드를 batched=True 플래그와 함께 사용해야 합니다. \n",
    "이것은 데이터셋의 길이를 변경하는 작업이기 때문에 여기에서 필요한 작업입니다. 하나의 예제가 여러 교육 피처를 생성할 수 있기 때문입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e83a467e-514e-4ddd-8b46-10c4e48a3c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 88524)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "238cddf8-a586-49e2-8cd7-3e089c4fed61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n검증 데이터를 전처리하는 작업은 라벨을 생성할 필요가 없기 때문에 약간 더 쉬울 것입니다 \\n(검증 손실을 계산하려는 경우에만 라벨을 생성해야 하지만 그 숫자는 모델의 성능을 이해하는 데 도움이 되지 않을 것입니다). \\n실제 즐거움은 모델의 예측을 원래 문맥의 범위로 해석하는 것입니다. \\n이를 위해 offset 매핑과 각 생성된 피처를 원본 예제와 일치시키는 방법이 필요합니다. \\n원본 데이터셋에 ID 열이 있으므로 해당 ID를 사용할 것입니다.\\n\\n여기에 추가할 것은 offset 매핑을 약간 정리하는 작업뿐입니다. \\n이러한 매핑에는 질문과 문맥에 대한 오프셋이 포함되지만 후속 처리 단계에서는 입력 ID의 어떤 부분이 문맥에 해당하고 어떤 부분이 질문인지 알 방법이 없습니다 \\n(우리가 사용한 sequence_ids() 메서드는 토큰화기의 출력에만 사용할 수 있습니다). 따라서 질문에 해당하는 오프셋을 None으로 설정할 것입니다.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "검증 데이터를 전처리하는 작업은 라벨을 생성할 필요가 없기 때문에 약간 더 쉬울 것입니다 \n",
    "(검증 손실을 계산하려는 경우에만 라벨을 생성해야 하지만 그 숫자는 모델의 성능을 이해하는 데 도움이 되지 않을 것입니다). \n",
    "실제 즐거움은 모델의 예측을 원래 문맥의 범위로 해석하는 것입니다. \n",
    "이를 위해 offset 매핑과 각 생성된 피처를 원본 예제와 일치시키는 방법이 필요합니다. \n",
    "원본 데이터셋에 ID 열이 있으므로 해당 ID를 사용할 것입니다.\n",
    "\n",
    "여기에 추가할 것은 offset 매핑을 약간 정리하는 작업뿐입니다. \n",
    "이러한 매핑에는 질문과 문맥에 대한 오프셋이 포함되지만 후속 처리 단계에서는 입력 ID의 어떤 부분이 문맥에 해당하고 어떤 부분이 질문인지 알 방법이 없습니다 \n",
    "(우리가 사용한 sequence_ids() 메서드는 토큰화기의 출력에만 사용할 수 있습니다). 따라서 질문에 해당하는 오프셋을 None으로 설정할 것입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff433020-103a-4d74-9c15-3f76d8bdb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76def918-037d-46f8-972f-044335209dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이러한 함수를 이전과 같이 검증 데이터셋 전체에 적용할 수 있습니다.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"이러한 함수를 이전과 같이 검증 데이터셋 전체에 적용할 수 있습니다.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fab981a9-7eac-4f06-b7ae-6619dd49acc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10570, 10784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8a042e2-262d-49a5-a588-99e7fa513ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'모든 데이터를 전처리했으므로 이제 훈련에 진입할 수 있습니다.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"모든 데이터를 전처리했으므로 이제 훈련에 진입할 수 있습니다.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe90878-756a-4baa-b923-6a47b44fe398",
   "metadata": {},
   "source": [
    "## Fine-tuning the model with the Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4335210c-8776-4e05-8df6-19e20bc9c3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Small validation dataset으로 evaluate'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Small validation dataset으로 evaluate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69aea399-125b-4f2c-a33c-72ab741a5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SQuAD 용으로 학습된 distilbert로 evaluate 할거여서 tokenizer 불러오기\"\"\"\n",
    "small_eval_set = raw_datasets[\"validation\"].select(range(100))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7c3dcdf-776c-4b63-a5e6-5413ae12d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_checkpoint = \"distilbert-base-uncased\"\n",
    "\"\"\"나중에 fine-tuning은 SQuAD로 학습된 거로 안할꺼니까 다시 바꿔주기\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c41874e4-f854-45f0-b937-b0579f701e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "\n",
    "\"\"\"SQuAD로 이미 학습된 distilbert model 불러오기\"\"\"\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc03b7e1-29a6-49da-b348-b7f45df11358",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e336cd36-b3ff-4d33-9166-ee9b67605e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60b132e5-cf86-48eb-8f97-67c89f666405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in small_eval_set:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d959830-d6a5-4187-a2e7-47b19228257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Huging Face에서 제공하는 library로 evaluate\"\"\"\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9539d054-9bcc-4d9b-9c5b-7f0e5bff4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65058769-4631-4fc9-b45d-033bbfcaf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}\n",
      "{'id': '56be4db0acb8001400a502ec', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n"
     ]
    }
   ],
   "source": [
    "print(predicted_answers[0])\n",
    "print(theoretical_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c901a07-16c0-4f44-8975-2364854c8d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"SQuAD dataset에 대해서 잘 학습된 model의 evaluate score\"\"\"\n",
    "metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc234e63-b05b-489f-959f-fa4411cf1500",
   "metadata": {},
   "source": [
    "<img src='./distilbert_result.png'></img>\n",
    "</br>\n",
    "DistilBERT paper에서 작성한 결과 table이다. </br>SQuAD 1.1 dataset에 대해서, <strong>79.1/86.9(Exact Match/F1 score)</strong>를 달성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e552d1f-9980-4586-9480-248b57291624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hugging Face의 evaluate method 구현\"\"\"\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc18ccee-2a47-4d2a-a45c-b4e7390515a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc06f972361744918517c9b696640227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(start_logits, end_logits, eval_set, small_eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86a006-9cf4-4f24-8c45-9eb7ec62bb5c",
   "metadata": {},
   "source": [
    "## Fine-tuning the model\n",
    "이전 section에선, 이미 SQuAD dataset으로 학습된 distilbert를 이용해서 결과를 미리 확인해봤다. </br>\n",
    "이번 section에서는 직접 fine-tuning을 해보는 section이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "add7bad7-e9aa-4083-81a4-cd36a8f4565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(model_checkpoint)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15f50872-c658-4eab-8246-6fd33a2879cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d33b3cee5de40e8af1e6338ce1d6060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0596a939-4be2-4e9c-a258-9b9ef6f482cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b176619c-c9f9-4f80-b1fa-35342b588cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"distilbert-finetuned-squad-test2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    #fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb2cfb02-8399-4858-ae5e-9cd6560ad202",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "다음의 ERROR가 발생해서 추가\n",
    "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
    "To disable this warning, you can either:\n",
    "\t- Avoid using `tokenizers` before the fork if possible\n",
    "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f06dd62-9bad-4483-838a-1fd2bdaabdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d8bce20, raw_cell=\"os.environ[\"WANDB_START_METHOD\"]='thread'\" store_history=True silent=False shell_futures=True cell_id=1f06dd62-9bad-4483-838a-1fd2bdaabdc1>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d8bcbb0, execution_count=62 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d8bce20, raw_cell=\"os.environ[\"WANDB_START_METHOD\"]='thread'\" store_history=True silent=False shell_futures=True cell_id=1f06dd62-9bad-4483-838a-1fd2bdaabdc1> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_START_METHOD\"]='thread'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9b6edd3-e8c5-4d02-9e68-6c485f5fbe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. \n",
    "Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
    "\"\"\"\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f339fdb-c9bc-4614-ab6f-bec4a6fc732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command창에서 실행\n",
    "#wandb login --relogin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f02c97b4-f657-45ba-9d0d-c9f123641c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed0b4f38-b6c1-4c28-a0a9-d967134c6670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqkrwnstj300\u001b[0m (\u001b[33mqkrwnstj\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/qkrwnstj/backup/DistilBERT/wandb/run-20231104_143110-5rs2g37a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qkrwnstj/huggingface/runs/5rs2g37a' target=\"_blank\">copper-wood-3</a></strong> to <a href='https://wandb.ai/qkrwnstj/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qkrwnstj/huggingface' target=\"_blank\">https://wandb.ai/qkrwnstj/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qkrwnstj/huggingface/runs/5rs2g37a' target=\"_blank\">https://wandb.ai/qkrwnstj/huggingface/runs/5rs2g37a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-WS-C621E-SAGE-Series:3239038:3239038 [0] NCCL INFO cudaDriverVersion 11040\n",
      "user-WS-C621E-SAGE-Series:3239038:3239038 [0] NCCL INFO Bootstrap : Using enp6s0:210.94.179.16<0>\n",
      "user-WS-C621E-SAGE-Series:3239038:3239038 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "NCCL version 2.14.3+cuda11.8\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Failed to open libibverbs.so[.1]\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO NET/Socket : Using [0]enp6s0:210.94.179.16<0>\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Using network Socket\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Using network Socket\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Using network Socket\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Using network Socket\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] misc/nvmlwrap.cc:98 NCCL WARN nvmlInit_v2() failed: Driver/library version mismatch\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO misc/nvmlwrap.cc:179 -> 2\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] graph/xml.cc:634 NCCL WARN No NVML device handle. Skipping nvlink detection.\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,ffff0000\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Setting affinity for GPU 3 to ffff0000,ffff0000\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Setting affinity for GPU 0 to ffff,0000ffff\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Setting affinity for GPU 1 to ffff,0000ffff\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Channel 00/02 :    0   1   2   3\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Channel 01/02 :    0   1   2   3\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Channel 00 : 0[3b000] -> 1[5e000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Channel 00 : 2[86000] -> 3[af000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Channel 00 : 3[af000] -> 0[3b000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Channel 01 : 0[3b000] -> 1[5e000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Channel 00 : 1[5e000] -> 2[86000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Channel 01 : 2[86000] -> 3[af000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Channel 01 : 3[af000] -> 0[3b000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Channel 01 : 1[5e000] -> 2[86000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Connected all rings\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Connected all rings\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Connected all rings\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Connected all rings\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Channel 00 : 3[af000] -> 2[86000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Channel 01 : 3[af000] -> 2[86000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Channel 00 : 2[86000] -> 1[5e000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Channel 01 : 2[86000] -> 1[5e000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Channel 00 : 1[5e000] -> 0[3b000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Channel 01 : 1[5e000] -> 0[3b000] via SHM/direct/direct\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO Connected all trees\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO Connected all trees\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO Connected all trees\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO Connected all trees\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n",
      "user-WS-C621E-SAGE-Series:3239038:3239464 [2] NCCL INFO comm 0x5620b69ad940 rank 2 nranks 4 cudaDev 2 busId 86000 - Init COMPLETE\n",
      "user-WS-C621E-SAGE-Series:3239038:3239465 [3] NCCL INFO comm 0x5620b69a4580 rank 3 nranks 4 cudaDev 3 busId af000 - Init COMPLETE\n",
      "user-WS-C621E-SAGE-Series:3239038:3239462 [0] NCCL INFO comm 0x5620b696c870 rank 0 nranks 4 cudaDev 0 busId 3b000 - Init COMPLETE\n",
      "user-WS-C621E-SAGE-Series:3239038:3239463 [1] NCCL INFO comm 0x5620b7a770e0 rank 1 nranks 4 cudaDev 1 busId 5e000 - Init COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4152' max='4152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4152/4152 21:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.493200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.119000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/qkrwnstj/anaconda3/envs/distilbert/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4152, training_loss=1.3141003316537494, metrics={'train_runtime': 1308.8918, 'train_samples_per_second': 202.898, 'train_steps_per_second': 3.172, 'total_flos': 2.602335381127373e+16, 'train_loss': 1.3141003316537494, 'epoch': 3.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f50d47bd130, execution_count=56 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f51e18d3af0, raw_cell=\"from transformers import Trainer\n",
      "\n",
      "trainer = Traine..\" store_history=True silent=False shell_futures=True cell_id=ed0b4f38-b6c1-4c28-a0a9-d967134c6670> result=TrainOutput(global_step=4152, training_loss=1.3141003316537494, metrics={'train_runtime': 1308.8918, 'train_samples_per_second': 202.898, 'train_steps_per_second': 3.172, 'total_flos': 2.602335381127373e+16, 'train_loss': 1.3141003316537494, 'epoch': 3.0})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16a391-a6c4-4a57-9a9f-88ae2f9b7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "모델을 평가하기 위해 학습이 완료되면 predict() 메서드를 사용하여 모델의 예측을 가져올 수 있습니다. \n",
    "이 메서드는 튜플을 반환하며, 첫 번째 요소는 모델의 예측값입니다 (여기서는 시작 및 종료 로짓의 쌍). 이 값을 compute_metrics() 함수로 보내서 모델을 평가합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39ba9afa-f3fe-492d-9688-521d4328ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528e96d3d0, raw_cell=\"predictions, _, _ = trainer.predict(validation_dat..\" store_history=True silent=False shell_futures=True cell_id=39ba9afa-f3fe-492d-9688-521d4328ce8d>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8d77addf3c4dc38692f631f4493f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 74.8155156102176, 'f1': 83.53339500367704}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528e96d9d0, execution_count=57 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528e96d3d0, raw_cell=\"predictions, _, _ = trainer.predict(validation_dat..\" store_history=True silent=False shell_futures=True cell_id=39ba9afa-f3fe-492d-9688-521d4328ce8d> result={'exact_match': 74.8155156102176, 'f1': 83.53339500367704}>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9991765e-d327-4ee7-9d96-455a02187576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f511c1c8bb0, raw_cell=\"trainer.push_to_hub(commit_message=\"Training compl..\" store_history=True silent=False shell_futures=True cell_id=9991765e-d327-4ee7-9d96-455a02187576>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e37ff1a8154560ae436bcbacfee16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/qkrwnstj/distilbert-finetuned-squad-test2/tree/main/'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d8f2cd0, execution_count=58 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f511c1c8bb0, raw_cell=\"trainer.push_to_hub(commit_message=\"Training compl..\" store_history=True silent=False shell_futures=True cell_id=9991765e-d327-4ee7-9d96-455a02187576> result='https://huggingface.co/qkrwnstj/distilbert-finetuned-squad-test2/tree/main/'>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d3d92-9cec-4b6e-8635-0cb7929737e7",
   "metadata": {},
   "source": [
    "# Custom Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589b414-3acc-471c-a30c-ad08293b5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "데이터 형식을 torch로 설정하고 모델에서 사용되지 않는 검증 데이터셋의 열을 제거한다.\n",
    "그 후, transformers에서 제공하는 default_data_collator를 collate_fn으로 사용하여 훈련 데이터셋을 섞고 \n",
    "검증 데이터셋은 섞지 않습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9ae098a-f400-4e28-bb23-8f9aa49bb687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d1fa850, raw_cell=\"from torch.utils.data import DataLoader\n",
      "from trans..\" store_history=True silent=False shell_futures=True cell_id=b9ae098a-f400-4e28-bb23-8f9aa49bb687>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d1fa6d0, execution_count=59 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d1fa850, raw_cell=\"from torch.utils.data import DataLoader\n",
      "from trans..\" store_history=True silent=False shell_futures=True cell_id=b9ae098a-f400-4e28-bb23-8f9aa49bb687> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "validation_set.set_format(\"torch\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=default_data_collator,\n",
    "    batch_size=32,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    validation_set, collate_fn=default_data_collator, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "489ea90c-2bb7-467e-af55-a3417c9afe89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d916580, raw_cell=\"model = AutoModelForQuestionAnswering.from_pretrai..\" store_history=True silent=False shell_futures=True cell_id=489ea90c-2bb7-467e-af55-a3417c9afe89>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d916a30, execution_count=60 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d916580, raw_cell=\"model = AutoModelForQuestionAnswering.from_pretrai..\" store_history=True silent=False shell_futures=True cell_id=489ea90c-2bb7-467e-af55-a3417c9afe89> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "928133b3-9075-4258-bad3-0e651ab96a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d8f2d90, raw_cell=\"from torch.optim import AdamW\n",
      "\n",
      "optimizer = AdamW(m..\" store_history=True silent=False shell_futures=True cell_id=928133b3-9075-4258-bad3-0e651ab96a0c>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d8f2df0, execution_count=63 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d8f2d90, raw_cell=\"from torch.optim import AdamW\n",
      "\n",
      "optimizer = AdamW(m..\" store_history=True silent=False shell_futures=True cell_id=928133b3-9075-4258-bad3-0e651ab96a0c> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8638a054-7242-43ee-8729-0146dc138a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d1fa820, raw_cell=\"from accelerate import Accelerator\n",
      "\n",
      "accelerator = ..\" store_history=True silent=False shell_futures=True cell_id=8638a054-7242-43ee-8729-0146dc138a57>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d1fa850, execution_count=65 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d1fa820, raw_cell=\"from accelerate import Accelerator\n",
      "\n",
      "accelerator = ..\" store_history=True silent=False shell_futures=True cell_id=8638a054-7242-43ee-8729-0146dc138a57> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d48503b-3461-4ee8-9aad-aee44e2b6850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d6fcbe0, raw_cell=\"from transformers import get_scheduler\n",
      "\n",
      "num_train_..\" store_history=True silent=False shell_futures=True cell_id=9d48503b-3461-4ee8-9aad-aee44e2b6850>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d6fc610, execution_count=66 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d6fcbe0, raw_cell=\"from transformers import get_scheduler\n",
      "\n",
      "num_train_..\" store_history=True silent=False shell_futures=True cell_id=9d48503b-3461-4ee8-9aad-aee44e2b6850> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8087666d-93ad-4433-b911-ce4708f3238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d6fc5e0, raw_cell=\"from huggingface_hub import Repository, get_full_r..\" store_history=True silent=False shell_futures=True cell_id=8087666d-93ad-4433-b911-ce4708f3238c>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'qkrwnstj/bert-finetuned-squad-accelerate'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f528d6fcc10, execution_count=67 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f528d6fc5e0, raw_cell=\"from huggingface_hub import Repository, get_full_r..\" store_history=True silent=False shell_futures=True cell_id=8087666d-93ad-4433-b911-ce4708f3238c> result='qkrwnstj/bert-finetuned-squad-accelerate'>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"bert-finetuned-squad-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44095d91-4a6c-4fbd-85d6-bba0edbe5319",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Repository' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-finetuned-squad-accelerate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m repo \u001b[38;5;241m=\u001b[39m \u001b[43mRepository\u001b[49m(output_dir, clone_from\u001b[38;5;241m=\u001b[39mrepo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Repository' is not defined"
     ]
    }
   ],
   "source": [
    "output_dir = \"bert-finetuned-squad-accelerate\"\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a3bd4-40ae-415c-af75-530a51522e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f50d41d2190>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f528d6fc8b0, raw_cell=\"from tqdm.auto import tqdm\n",
      "import torch\n",
      "\n",
      "progress_..\" store_history=True silent=False shell_futures=True cell_id=af4a3bd4-40ae-415c-af75-530a51522e57>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044f694113184c81b3e3c1973a6e003b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    accelerator.print(\"Evaluation!\")\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())\n",
    "        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())\n",
    "\n",
    "    start_logits = np.concatenate(start_logits)\n",
    "    end_logits = np.concatenate(end_logits)\n",
    "    start_logits = start_logits[: len(validation_dataset)]\n",
    "    end_logits = end_logits[: len(validation_dataset)]\n",
    "\n",
    "    metrics = compute_metrics(\n",
    "        start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"]\n",
    "    )\n",
    "    print(f\"epoch {epoch}:\", metrics)\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89343076-04a1-411d-b11f-649102477114",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d2176-28d5-4814-ac47-51e0917f1c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"qkrwnstj/bert-finetuned-squad\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "\n",
    "context = \"\"\"\n",
    "🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back 🤗 Transformers?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilbert",
   "language": "python",
   "name": "distilbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
